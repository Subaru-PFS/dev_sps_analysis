{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    %matplotlib notebook\n",
    "    figsize = (10,6)\n",
    "else:\n",
    "    figsize = (12,8)\n",
    "\n",
    "from sps_engineering_Lib_dataQuery.databasemanager import DatabaseManager\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from matplotlib.dates import num2date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierMask(array, outlierConstant=2.):\n",
    "    lowerQuartile = np.percentile(array, 25)\n",
    "    upperQuartile = np.percentile(array, 75)\n",
    "    IQR = (upperQuartile - lowerQuartile) * outlierConstant\n",
    "\n",
    "    return np.logical_and(array >= lowerQuartile - IQR, array <= upperQuartile + IQR)\n",
    "\n",
    "\n",
    "def interpdate(datas):\n",
    "    \n",
    "    mintai = np.max([data.tai.min() for data in datas])\n",
    "    maxtai = np.min([data.tai.max() for data in datas])\n",
    "    tai = np.arange(mintai, maxtai, 0.0002)\n",
    "    res = pd.DataFrame({'tai':tai})\n",
    "    for data in datas:\n",
    "        data = data.dropna()\n",
    "        for col in data.columns[2:]:\n",
    "            mask = outlierMask(data[col].values)\n",
    "            nbOut = np.sum(~mask)\n",
    "            if nbOut:\n",
    "                print('col=%s nbOutliers=%d/%d'%(col, nbOut, len(mask)))\n",
    "            res[col] = np.interp(res['tai'], data['tai'].values[mask], data[col].values[mask])\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration 20°C step date\n",
    "\n",
    "dates = {1:('2019-01-25 14:30', '2019-01-25 17:30'),\n",
    "         2:('2019-01-30 17:30', '2019-01-30 20:30'),\n",
    "         3:('2019-02-05 17:30', '2019-02-05 20:30'),\n",
    "         4:('2019-02-11 13:30', '2019-02-11 16:30')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatabaseManager('tron', 5432, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['val1_%d'%i for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SM Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specId = 4\n",
    "doCalc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestart, dateend = dates[specId]\n",
    "\n",
    "datafile = '/home/pfs/dev/SM_calibTemps/%s-SM%d-calibTemps_data.csv'%(datestart[:10], specId)\n",
    "poptfile = '/home/pfs/dev/SM_calibTemps/%s-SM%d-calibTemps_popt.csv'%(datestart[:10], specId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically Create 15,10,5,0 steps date\n",
    "\n",
    "tempSteps = [15, 10, 5, 0] if specId != 3 else [15, 10, 5]\n",
    "steps = {20: [datestart, dateend]}\n",
    "\n",
    "for i, temp in enumerate(tempSteps):\n",
    "    delta = dt.timedelta(hours=(i + 1) * 9)\n",
    "    newstart = (dt.datetime.strptime(datestart, '%Y-%m-%d %H:%M') + delta).strftime('%Y-%m-%d %H:%M')\n",
    "    newend = (dt.datetime.strptime(dateend, '%Y-%m-%d %H:%M') + delta).strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    steps[temp] = [newstart, newend]\n",
    "\n",
    "if specId == 3:\n",
    "    newstart, newend = '2019-02-07 09:30', '2019-02-07 12:30'\n",
    "    steps[0] = [newstart, newend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the steps are correct\n",
    "if doCalc:\n",
    "    std = []\n",
    "\n",
    "    for start, end in steps.values():\n",
    "        ref = db.dataBetween('aitroom__lake1', cols='temp1', start=start, end=end)\n",
    "        stage1 = db.dataBetween('enu_sm0__temps1', cols=','.join(cols), start=start, end=end)\n",
    "        stage2 = db.dataBetween('enu_sm0__temps2', cols=','.join(cols), start=start, end=end)\n",
    "        stage1.columns = ['id','tai'] + ['%d'%i for i in range(101,111)]\n",
    "        stage2.columns = ['id','tai'] + ['%d'%i for i in range(201,211)]\n",
    "        datatemp = (interpdate([ref, stage1, stage2])).rolling(window=4,center=False).median().dropna()\n",
    "        std.append(tuple([datatemp[col].std() for col in datatemp.columns[1:]]))\n",
    "\n",
    "    std = pd.DataFrame(std, columns=datatemp.columns[1:])\n",
    "    stdmean = np.mean(std.values)\n",
    "\n",
    "    print('specId=%d, stdmean=%.7e'%(specId, stdmean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract reference temperature and sm sensors resistance, save the median\n",
    "if doCalc:\n",
    "    ohms = []\n",
    "    datasets = []\n",
    "\n",
    "    for start, end in steps.values():\n",
    "        ref = db.dataBetween('aitroom__flowduino', cols='flow', start=start, end=end)\n",
    "        ref.columns = ['id', 'tai'] + ['refTemp']\n",
    "        print('%.3f+-%.3f' % (ref.refTemp.mean(), ref.refTemp.std()))\n",
    "        stage1 = db.dataBetween('enu_sm0__res1', cols=','.join(cols), start=start, end=end)\n",
    "        stage2 = db.dataBetween('enu_sm0__res2', cols=','.join(cols), start=start, end=end)\n",
    "        stage1.columns = ['id', 'tai'] + ['%d' % i for i in range(101, 111)]\n",
    "        stage2.columns = ['id', 'tai'] + ['%d' % i for i in range(201, 211)]\n",
    "        dataset = interpdate([ref, stage1, stage2])\n",
    "        ohms.append(tuple([dataset[col].median() for col in dataset.columns[1:]]))\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    datasets = pd.concat(datasets)\n",
    "    ohms = pd.DataFrame(ohms, columns=dataset.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doCalc:\n",
    "    popts = []\n",
    "    temps = [ohms['refTemp'].values]\n",
    "\n",
    "    for col in ohms.columns[1:]:\n",
    "        popts.append(np.polyfit(ohms[col], ohms['refTemp'], deg=3))\n",
    "        temps.append(np.polyval(popts[-1], ohms[col])-ohms['refTemp'].values)\n",
    "\n",
    "    popts = pd.DataFrame(popts, index=dataset.columns[2:], columns=['c1', 'c2', 'c3', 'c4'])\n",
    "    temps = pd.DataFrame(np.array(temps).transpose(), columns=ohms.columns)\n",
    "\n",
    "    temps.set_index('refTemp').plot(figsize=(12,10), subplots=False, grid=True, title='Fit error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doCalc:\n",
    "    datasets['tai'] = [date.isoformat()[:19] for date in num2date(datasets.tai)]\n",
    "    datasets.to_csv(datafile)\n",
    "    popts.to_csv(poptfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot error with uncorrected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for start, end in steps.values():\n",
    "    ref = db.dataBetween('aitroom__lake1', cols='temp1', start=start, end=end)\n",
    "    ref.columns = ['id', 'tai'] + ['refTemp']\n",
    "    stage1 = db.dataBetween('enu_sm0__temps1', cols=','.join(cols), start=datestart, end=dateend)\n",
    "    stage2 = db.dataBetween('enu_sm0__temps2', cols=','.join(cols), start=datestart, end=dateend)\n",
    "    stage1.columns = ['id', 'tai'] + ['%d' % i for i in range(101, 111)]\n",
    "    stage2.columns = ['id', 'tai'] + ['%d' % i for i in range(201, 211)]\n",
    "    \n",
    "    dataset = interpdate([ref, stage1, stage2])\n",
    "    datasets.append(dataset)\n",
    "\n",
    "datasets = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "for ref in datasets.columns[1:]:\n",
    "    temp = datasets.drop(columns=['tai', ref])\n",
    "    for col in temp.columns:\n",
    "        mat = np.abs(datasets[col] - datasets[ref])\n",
    "        error.append((np.mean(mat), np.median(mat), np.max(mat)))\n",
    "    \n",
    "error = pd.DataFrame(error, columns=['mean','median','max'])\n",
    "error.plot(figsize=figsize, grid=True, title='SM%d Error between sensors'%specId)\n",
    "\n",
    "plt.ylabel('Error (°C)')\n",
    "plt.savefig('/home/pfs/dev/SM_calibTemps/SM%d_errorNoCalib.png'%specId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Plot error with corrected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract reference temperature and sm sensors resistance and recalibrate\n",
    "popts = pd.read_csv(poptfile, index_col=0)\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for start, end in steps.values():\n",
    "    ref = db.dataBetween('aitroom__flowduino', cols='flow', start=start, end=end)\n",
    "    ref.columns = ['id', 'tai'] + ['refTemp']\n",
    "    stage1 = db.dataBetween('enu_sm0__res1', cols=','.join(cols), start=start, end=end)\n",
    "    stage2 = db.dataBetween('enu_sm0__res2', cols=','.join(cols), start=start, end=end)\n",
    "    stage1.columns = ['id', 'tai'] + ['%d' % i for i in range(101, 111)]\n",
    "    stage2.columns = ['id', 'tai'] + ['%d' % i for i in range(201, 211)]\n",
    "    \n",
    "    dataset = interpdate([ref, stage1, stage2])\n",
    "    for col, popt in popts.iterrows():\n",
    "        dataset[str(col)] = np.polyval(popt, dataset[str(col)])\n",
    "\n",
    "    datasets.append(dataset)\n",
    "\n",
    "datasets = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "for ref in datasets.columns[1:]:\n",
    "    temp = datasets.drop(columns=['tai', ref])\n",
    "    for col in temp.columns:\n",
    "        mat = np.abs(datasets[col] - datasets[ref])\n",
    "        error.append((np.mean(mat), np.median(mat), np.max(mat)))\n",
    "    \n",
    "error = pd.DataFrame(error, columns=['mean','median','max'])\n",
    "error.plot(figsize=figsize, grid=True, title='SM%d Error between calibrated sensors'%specId)\n",
    "plt.ylabel('Error (°C)')\n",
    "plt.savefig('/home/pfs/dev/SM_calibTemps/SM%d_errorWithCalib.png'%specId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popts=pd.read_csv(poptfile, index_col=0)\n",
    "datasets = []\n",
    "\n",
    "start=datestart\n",
    "end = (dt.datetime.strptime(newend, '%Y-%m-%d %H:%M') + dt.timedelta(days=2)).strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "ref = db.dataBetween('aitroom__flowduino', cols='flow', start=start, end=end)\n",
    "ref.columns = ['id','tai'] + ['refTemp']\n",
    "stage1 = db.dataBetween('enu_sm0__res1', cols=','.join(cols), start=start, end=end)\n",
    "stage2 = db.dataBetween('enu_sm0__res2', cols=','.join(cols), start=start, end=end)\n",
    "stage1.columns = ['id','tai'] + ['%d'%i for i in range(101,111)]\n",
    "stage2.columns = ['id','tai'] + ['%d'%i for i in range(201,211)]\n",
    "datasets.append(interpdate([ref, stage1, stage2]))\n",
    "    \n",
    "datasets = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, popt in popts.iterrows():\n",
    "    datasets[str(col)] = np.polyval(popt, datasets[str(col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "for col in datasets.columns[1:]:\n",
    "    plt.plot_date(datasets.tai, datasets[col],'o', label='channel %s'%(col))\n",
    "    \n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.ylim(-1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel, (c1,c2,c3,c4) in popts.iterrows():\n",
    "    print('%s=%.7e,%7e,%.7e,%.7e'%(channel,c1,c2,c3,c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
